{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUDyvmEfaI1RL98/K/wFba",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anirudhsaroha/MLexperiment/blob/main/AnirudhSaroha23CS055_experiment5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbeuAoBl-Ia7",
        "outputId": "4e2c60ff-3876-4f15-ccff-d6d0ad3cb66d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting ucimlrepo\n",
            "  Downloading ucimlrepo-0.0.7-py3-none-any.whl.metadata (5.5 kB)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2.2.2)\n",
            "Requirement already satisfied: certifi>=2020.12.5 in /usr/local/lib/python3.12/dist-packages (from ucimlrepo) (2025.10.5)\n",
            "Requirement already satisfied: numpy>=1.26.0 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas>=1.0.0->ucimlrepo) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas>=1.0.0->ucimlrepo) (1.17.0)\n",
            "Downloading ucimlrepo-0.0.7-py3-none-any.whl (8.0 kB)\n",
            "Installing collected packages: ucimlrepo\n",
            "Successfully installed ucimlrepo-0.0.7\n"
          ]
        }
      ],
      "source": [
        "!pip install ucimlrepo\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
        "\n",
        "# Load dataset\n",
        "adult = fetch_ucirepo(id=2)\n",
        "X = adult.data.features\n",
        "y = adult.data.targets.iloc[:, 0]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 2. DATA PREPROCESSING\n",
        "# Handle missing values (replace '?' with NaN then drop)\n",
        "X = X.replace('?', np.nan).dropna()\n",
        "y = y[X.index]  # Align targets\n",
        "\n",
        "# Label encode categorical columns\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "for col in X.select_dtypes(include=['object']).columns:\n",
        "    X[col] = LabelEncoder().fit_transform(X[col])\n",
        "\n",
        "# Convert to numpy\n",
        "X = X.to_numpy()\n",
        "y = np.where(y == '>50K', 1, 0)\n",
        "\n",
        "# Split: 80% Train / 20% Temp â†’ then split Temp into 50/50 = 10% Val / 10% Test\n",
        "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)"
      ],
      "metadata": {
        "id": "QSpAeSlQ-SYl"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 3 DECISION TREE FROM SCRATCH\n",
        "class DecisionTree:\n",
        "    def _init_(self, max_depth=None, min_samples_split=5, criterion=\"gini\"):\n",
        "        self.max_depth = max_depth\n",
        "        self.min_samples_split = min_samples_split\n",
        "        self.criterion = criterion\n",
        "        self.tree = None\n",
        "\n",
        "    # Impurity Functions\n",
        "    def _gini(self, y):\n",
        "        p = np.bincount(y) / len(y)\n",
        "        return 1 - np.sum(p ** 2)\n",
        "\n",
        "    def _entropy(self, y):\n",
        "        p = np.bincount(y) / len(y)\n",
        "        p = p[p > 0]\n",
        "        return -np.sum(p * np.log2(p))\n",
        "\n",
        "    def _impurity(self, y):\n",
        "        return self._gini(y) if self.criterion == \"gini\" else self._entropy(y)\n",
        "\n",
        "    # Best Split Finder\n",
        "    def _best_split(self, X, y):\n",
        "        best_gain, best_feat, best_thresh = 0, None, None\n",
        "        parent_impurity = self._impurity(y)\n",
        "\n",
        "        for feat in range(X.shape[1]):\n",
        "            values = np.unique(X[:, feat])\n",
        "            for thresh in values:\n",
        "                left = y[X[:, feat] <= thresh]\n",
        "                right = y[X[:, feat] > thresh]\n",
        "                if len(left) == 0 or len(right) == 0:\n",
        "                    continue\n",
        "                gain = parent_impurity - (\n",
        "                    (len(left) / len(y)) * self._impurity(left)\n",
        "                    + (len(right) / len(y)) * self._impurity(right)\n",
        "                )\n",
        "                if gain > best_gain:\n",
        "                    best_gain, best_feat, best_thresh = gain, feat, thresh\n",
        "\n",
        "        return best_feat, best_thresh\n",
        "\n",
        "    # Recursively Build Tree\n",
        "    def _build(self, X, y, depth=0):\n",
        "        # Leaf stop conditions\n",
        "        if (len(np.unique(y)) == 1) or \\\n",
        "           (self.max_depth is not None and depth >= self.max_depth) or \\\n",
        "           (len(y) < self.min_samples_split):\n",
        "            return np.bincount(y).argmax()  # Return class label\n",
        "\n",
        "        feat, thresh = self._best_split(X, y)\n",
        "\n",
        "        # If no valid split found - make leaf\n",
        "        if feat is None:\n",
        "            return np.bincount(y).argmax()\n",
        "\n",
        "        left_idx = X[:, feat] <= thresh\n",
        "        right_idx = X[:, feat] > thresh\n",
        "\n",
        "        return {\n",
        "            \"feature\": feat,\n",
        "            \"threshold\": thresh,\n",
        "            \"left\": self._build(X[left_idx], y[left_idx], depth + 1),\n",
        "            \"right\": self._build(X[right_idx], y[right_idx], depth + 1)\n",
        "        }\n",
        "\n",
        "    # Public Fit\n",
        "    def fit(self, X, y):\n",
        "        self.tree = self._build(X, y)\n",
        "\n",
        "    # Prediction for One Row\n",
        "    def _predict_one(self, x, node):\n",
        "        if not isinstance(node, dict):\n",
        "            return node  # Leaf reached (class label)\n",
        "\n",
        "        if x[node[\"feature\"]] <= node[\"threshold\"]:\n",
        "            return self._predict_one(x, node[\"left\"])\n",
        "        else:\n",
        "            return self._predict_one(x, node[\"right\"])\n",
        "\n",
        "    # Predict on Full Dataset\n",
        "    def predict(self, X):\n",
        "        return np.array([self._predict_one(x, self.tree) for x in X])"
      ],
      "metadata": {
        "id": "9HbeQW5a_U3c"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 4. TRAIN / VALIDATE\n",
        "model = DecisionTree(max_depth=4, criterion=\"entropy\")\n",
        "model.fit(X_train, y_train)\n",
        "y_pred = model.predict(X_val)\n",
        "\n",
        "print(\"Validation Accuracy:\", accuracy_score(y_val, y_pred))"
      ],
      "metadata": {
        "id": "PpEE9NYg_a7w"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 5. EVALUATION ON TEST SET\n",
        "y_test_pred = model.predict(X_test)\n",
        "print(\"\\nFinal Evaluation Metrics:\")\n",
        "print(\"Accuracy:\", accuracy_score(y_test, y_test_pred))\n",
        "print(\"Precision:\", precision_score(y_test, y_test_pred))\n",
        "print(\"Recall:\", recall_score(y_test, y_test_pred))\n",
        "print(\"F1-Score:\", f1_score(y_test, y_test_pred))\n",
        "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_test_pred))"
      ],
      "metadata": {
        "id": "vkoYT5Aa_gZr"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 6. COMPARE WITH SKLEARN\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "sk_model = DecisionTreeClassifier(max_depth=4, criterion=\"entropy\")\n",
        "sk_model.fit(X_train, y_train)\n",
        "sk_pred = sk_model.predict(X_test)\n",
        "\n",
        "print(\"\\n Sklearn Accuracy:\", accuracy_score(y_test, sk_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7Hy5aD2_kX6",
        "outputId": "e0df6ea9-8bab-40c6-9162-4f1938c1fc4e"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            " Sklearn Accuracy: 0.8485518461198319\n"
          ]
        }
      ]
    }
  ]
}